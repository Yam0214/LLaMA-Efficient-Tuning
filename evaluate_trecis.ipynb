{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_instruction: 1131\n",
      "max_input:       1496\n",
      "max_output:      66\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"llm_collections/Llama-2-7b-chat-hf\")\n",
    "\n",
    "max_instruction = 0\n",
    "max_input = 0\n",
    "max_output = 0\n",
    "with open(\"data/trecis/high_sampled_5000_test.json\", \"r\", encoding=\"utf8\") as file:\n",
    "    for data in json.load(file):\n",
    "        inst_len = len(tokenizer(data[\"instruction\"]).input_ids)\n",
    "        max_instruction = max(max_instruction, inst_len)\n",
    "        input_string = \"\"\"<s>[INST] <<SYS>>\\n\\n{system_prompt}\\n\\n<</SYS>>\\n\\n{user_message} [/INST]\"\"\".format(\n",
    "            system_prompt=\"\"\"<s> [INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\"\"\",\n",
    "    user_message=f\"{data['instruction']}\\n{data['input']}\"\n",
    "        )\n",
    "        input_len = len(tokenizer(input_string).input_ids)\n",
    "        max_input = max(max_input, input_len)\n",
    "        max_output = max(max_output, len(tokenizer(data[\"output\"]).input_ids))\n",
    "\n",
    "\n",
    "print(f\"max_instruction: {max_instruction}\")\n",
    "print(f\"max_input:       {max_input}\")\n",
    "print(f\"max_output:      {max_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1028fecd996491d9cc00de45a6ae2af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/169700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsered : total = 169700: 169700; num bad response = 0\n",
      "(6788, 25)\n",
      "macro f1: 0.4044971808933921\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "       Request-GoodsServices    0.05263   0.04348   0.04762        23\n",
      "     Request-SearchAndRescue    0.41379   0.40000   0.40678        30\n",
      "   Request-InformationWanted    0.19403   0.28261   0.23009        46\n",
      "      CallToAction-Volunteer    0.26786   0.46875   0.34091        32\n",
      "      CallToAction-Donations    0.50259   0.77600   0.61006       125\n",
      "     CallToAction-MovePeople    0.33523   0.76623   0.46640        77\n",
      "Report-FirstPartyObservation    0.16742   0.63731   0.26518       579\n",
      "Report-ThirdPartyObservation    0.34629   0.94336   0.50661      1889\n",
      "              Report-Weather    0.54167   0.80984   0.64915       915\n",
      "             Report-Location    0.49360   0.94992   0.64963      2556\n",
      "      Report-EmergingThreats    0.36211   0.77139   0.49286       783\n",
      "          Report-NewSubEvent    0.18408   0.12803   0.15102       289\n",
      "      Report-MultimediaShare    0.50351   0.97005   0.66293      2437\n",
      "     Report-ServiceAvailable    0.30511   0.71784   0.42822       241\n",
      "              Report-Factoid    0.47842   0.71540   0.57339      1286\n",
      "             Report-Official    0.23209   0.45251   0.30682       358\n",
      "                 Report-News    0.41006   0.95949   0.57457      2098\n",
      "              Report-CleanUp    0.37931   0.23913   0.29333        46\n",
      "             Report-Hashtags    0.53913   0.95554   0.68933      1687\n",
      "        Report-OriginalEvent    0.22008   0.38776   0.28079       441\n",
      " Other-ContextualInformation    0.22388   0.37428   0.28017       521\n",
      "                Other-Advice    0.27822   0.55352   0.37031       383\n",
      "             Other-Sentiment    0.38552   0.91639   0.54272      1220\n",
      "            Other-Discussion    0.18404   0.69651   0.29115       659\n",
      "            Other-Irrelevant    1.00000   0.00120   0.00240      1666\n",
      "\n",
      "                   micro avg    0.39256   0.76372   0.51857     20387\n",
      "                   macro avg    0.36003   0.59666   0.40450     20387\n",
      "                weighted avg    0.45759   0.76372   0.49830     20387\n",
      "                 samples avg    0.38488   0.64638   0.45880     20387\n",
      "\n",
      "0.404497\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f8e7d3522140aeb31ffe40774698fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsered : total = 125000: 125000; num bad response = 0\n",
      "(5000, 25)\n",
      "macro f1: 0.413598243324785\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "       Request-GoodsServices    0.53846   0.24138   0.33333        87\n",
      "     Request-SearchAndRescue    0.15686   0.29630   0.20513        27\n",
      "   Request-InformationWanted    0.48810   0.47953   0.48378       171\n",
      "      CallToAction-Volunteer    0.32673   0.54098   0.40741        61\n",
      "      CallToAction-Donations    0.47668   0.78632   0.59355       117\n",
      "     CallToAction-MovePeople    0.46067   0.60073   0.52146       273\n",
      "Report-FirstPartyObservation    0.15480   0.68120   0.25227       367\n",
      "Report-ThirdPartyObservation    0.24742   0.88638   0.38686      1109\n",
      "              Report-Weather    0.60806   0.77066   0.67977      1077\n",
      "             Report-Location    0.66674   0.93473   0.77831      3187\n",
      "      Report-EmergingThreats    0.28418   0.79673   0.41894       733\n",
      "          Report-NewSubEvent    0.13876   0.13551   0.13712       214\n",
      "      Report-MultimediaShare    0.38505   0.85684   0.53133      1425\n",
      "     Report-ServiceAvailable    0.56883   0.62584   0.59597       449\n",
      "              Report-Factoid    0.67824   0.72939   0.70288      1286\n",
      "             Report-Official    0.31780   0.45862   0.37544       580\n",
      "                 Report-News    0.27448   0.94322   0.42521      1180\n",
      "              Report-CleanUp    0.23636   0.26000   0.24762        50\n",
      "             Report-Hashtags    0.48898   0.93054   0.64108      1526\n",
      "        Report-OriginalEvent    0.19847   0.12787   0.15553       610\n",
      " Other-ContextualInformation    0.21978   0.06006   0.09434       333\n",
      "                Other-Advice    0.54462   0.69051   0.60894       769\n",
      "             Other-Sentiment    0.52059   0.87320   0.65229       970\n",
      "            Other-Discussion    0.06061   0.68657   0.11138       134\n",
      "            Other-Irrelevant    0.00000   0.00000   0.00000         0\n",
      "\n",
      "                   micro avg    0.40114   0.76935   0.52733     16735\n",
      "                   macro avg    0.36165   0.57572   0.41360     16735\n",
      "                weighted avg    0.46332   0.76935   0.55606     16735\n",
      "                 samples avg    0.40792   0.77532   0.51055     16735\n",
      "\n",
      "0.413598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ouyanghongyu/anaconda3/envs/torch2.0/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/home/ouyanghongyu/anaconda3/envs/torch2.0/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ouyanghongyu/anaconda3/envs/torch2.0/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ouyanghongyu/anaconda3/envs/torch2.0/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# easy to fine-tuning llama\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# fpath = \"records/chatglm2/chatglm_zeroshot_high_level/val_results.jsonl\"    #  0.28231\n",
    "# fpath = \"records/baichuan/baichuan_zeroshot_high_level/val_results.jsonl\"   # 0.33408\n",
    "# fpath = \"records/baichuan/baichuan_zeroshot_high_level_10/val_results.jsonl\"   # 0.33408\n",
    "# fpath = \"records/ernie-bot/ernie_bot_zeroshot_high_level/val_results.jsonl\"\n",
    "# fpath = \"records/ernie-bot/ernie_bot_zeroshot_high_level_gen_prompt/val_results.jsonl\" \n",
    "\n",
    "\n",
    "# 忽略大小写\n",
    "request_pattern = re.compile(\"request\", re.IGNORECASE)\n",
    "call_to_action_pattern = re.compile(r\"call[\\-\\_\\s]?(?:to|for)[\\-\\_\\s]?action\", re.IGNORECASE)\n",
    "report_pattern = re.compile(\"report\", re.IGNORECASE)\n",
    "other_pattern = re.compile(\"other\", re.IGNORECASE)\n",
    "\n",
    "true_pattern = re.compile(\"yes\", re.IGNORECASE)\n",
    "false_pattern = re.compile(\"no\", re.IGNORECASE)\n",
    "\n",
    "def soft_post_processing_top_level(response: str):\n",
    "    request = 1.0 if request_pattern.search(response) else 0.0\n",
    "    call_to_action = 1.0 if call_to_action_pattern.search(response) else 0.0\n",
    "    report = 1.0 if report_pattern.search(response) or re.search(\"报告\", response) else 0.0\n",
    "    other = 1.0 if other_pattern.search(response) else 0.0\n",
    "    # 修正\n",
    "    if request + call_to_action + report + other == 0 or request + call_to_action + report + other >= 4.0:\n",
    "        other = 1.0\n",
    "    \n",
    "    return [request, call_to_action, report, other]\n",
    "\n",
    "def multi_label_to_top_level(multi_label):\n",
    "    request = 1.0 if multi_label[:3].sum() > 0 else 0.0\n",
    "    call_to_action = 1.0 if multi_label[3:6].sum() > 0 else 0.0\n",
    "    report = 1.0 if multi_label[6:-5].sum() > 0 else 0.0\n",
    "    other = 1.0 if multi_label[-5:].sum() > 0 else 0.0\n",
    "    return [request, call_to_action, report, other]\n",
    "\n",
    "high_level_info_types = [\n",
    "    'Request-GoodsServices',\n",
    "    'Request-SearchAndRescue',\n",
    "    'Request-InformationWanted',\n",
    "    'CallToAction-Volunteer',\n",
    "    'CallToAction-Donations',\n",
    "    'CallToAction-MovePeople',\n",
    "    'Report-FirstPartyObservation',\n",
    "    'Report-ThirdPartyObservation',\n",
    "    'Report-Weather',\n",
    "    'Report-Location',\n",
    "    'Report-EmergingThreats',\n",
    "    'Report-NewSubEvent',\n",
    "    'Report-MultimediaShare',\n",
    "    'Report-ServiceAvailable',\n",
    "    'Report-Factoid',\n",
    "    'Report-Official',\n",
    "    'Report-News',\n",
    "    'Report-CleanUp',\n",
    "    'Report-Hashtags',\n",
    "    'Report-OriginalEvent',\n",
    "    'Other-ContextualInformation',\n",
    "    'Other-Advice',\n",
    "    'Other-Sentiment',\n",
    "    'Other-Discussion',\n",
    "    'Other-Irrelevant',\n",
    "    ]\n",
    "\n",
    "def soft_post_processing_high_level(response: str):\n",
    "    high_level_flag_list = [(info_type in response) for info_type in high_level_info_types]\n",
    "    return high_level_flag_list\n",
    "\n",
    "def soft_post_processing_inference(response: str):\n",
    "    if \"I'm just an AI\" in response:\n",
    "        # a bad response\n",
    "        return 0.0\n",
    "\n",
    "    true_flag = true_pattern.search(response)\n",
    "    return 1.0 if true_flag else 0.0\n",
    "\n",
    "def report_result_llama(fpath, intent_level=\"top\", task_type=\"mc\"):\n",
    "    soft_post_processing_map = {\n",
    "        \"high\": (soft_post_processing_high_level, high_level_info_types),\n",
    "        \"top\": (soft_post_processing_top_level, [\"request\", \"call-to-action\", \"report\", \"other\"])\n",
    "    }\n",
    "    soft_post_processing_fct, intent_labels = soft_post_processing_map[intent_level]\n",
    "\n",
    "    if task_type == \"if\":\n",
    "        soft_post_processing_fct = soft_post_processing_inference\n",
    "\n",
    "    if isinstance(fpath, str):\n",
    "        fpath = [fpath]\n",
    "    lines = []\n",
    "    for fp in fpath:\n",
    "        with open(fp, \"r\", encoding=\"utf8\") as file:\n",
    "            lines.extend(file.readlines())\n",
    "\n",
    "    predictions = []\n",
    "    ground_truths = []\n",
    "    bad_response_counter = 0\n",
    "    for line_str in tqdm(lines):\n",
    "        line = json.loads(line_str)\n",
    "        response = line[\"predict\"]\n",
    "        try:\n",
    "            pred_label = soft_post_processing_fct(response)\n",
    "        except Exception as e:\n",
    "            print(f\"【{line['label']}: {response}】 {e}\")\n",
    "        else:\n",
    "            if \"I'm just an AI\" in response:\n",
    "                bad_response_counter += 1\n",
    "            predictions.append(pred_label)\n",
    "            ground_truths.append(soft_post_processing_fct(line[\"label\"]))\n",
    "    \n",
    "    print(f\"parsered : total = {len(predictions)}: {len(lines)}; num bad response = {bad_response_counter}\")\n",
    "    if task_type == \"if\":\n",
    "        ground_truths = np.array(ground_truths).reshape(-1, 25)\n",
    "        predictions = np.array(predictions).reshape(-1, 25)\n",
    "        for idx in range(predictions.shape[0]):\n",
    "            if all(predictions[idx] == 0.0):\n",
    "                # 全 false\n",
    "                predictions[idx, -1] = 1.0\n",
    "            elif predictions[idx, -1] and any(predictions[idx, :-1]):\n",
    "                # 同时有 Irrelevant 和 其他标签\n",
    "                predictions[idx, -1] = 0.0\n",
    "\n",
    "    print(ground_truths.shape)\n",
    "    f1 = f1_score(ground_truths, predictions, average=\"macro\")\n",
    "    print(\"macro f1: {}\".format(f1))\n",
    "\n",
    "    report = classification_report(ground_truths, predictions, target_names=intent_labels , digits=5)\n",
    "    print(report)\n",
    "    return f1\n",
    "\n",
    "# for exp_dir in Path(\"records/chatglm2/\").glob(\"chatglm2_zeroshot_high_level_*\"):\n",
    "#     print(exp_dir.name)\n",
    "#     report_result(exp_dir / \"val_results.jsonl\")\n",
    "\n",
    "# exp_dir = Path(\"saves/LLaMA2-7B-Chat/lora/trecis-mc_if-train-random-1\")\n",
    "# f1_scores = []\n",
    "# for level in [\"top\", \"high\"]:\n",
    "#     for ds in [\"val\", \"test\"]:\n",
    "#         print(f\"{exp_dir.parents[1]} instruction tuning on {ds} set ({level})\")\n",
    "#         f1 = report_result_llama(\n",
    "#             exp_dir / f\"results_{ds}_{level}\" / \"generated_predictions.jsonl\",\n",
    "#             intent_level=level\n",
    "#             )\n",
    "#         f1_scores.append(f1)\n",
    "\n",
    "# print(\"{:.6f}|{:.6f}|{:.6f}|{:.6f}|\".format(*f1_scores))\n",
    "\n",
    "train_task_tag = \"trecis-mc-train-random-1\"\n",
    "f1 = report_result_llama(\n",
    "    [\n",
    "        f\"saves/LLaMA2-7B-Chat/lora/{train_task_tag}/results_if_val_high_0/generated_predictions.jsonl\",\n",
    "        f\"saves/LLaMA2-7B-Chat/lora/{train_task_tag}/results_if_val_high_1/generated_predictions.jsonl\",\n",
    "    ],\n",
    "    intent_level=\"high\",\n",
    "    task_type=\"if\"\n",
    "    )\n",
    "print(f\"{f1:.6f}\")\n",
    "\n",
    "f1 = report_result_llama(\n",
    "    [\n",
    "        f\"saves/LLaMA2-7B-Chat/lora/{train_task_tag}/results_if_test_high_0/generated_predictions.jsonl\",\n",
    "        f\"saves/LLaMA2-7B-Chat/lora/{train_task_tag}/results_if_test_high_1/generated_predictions.jsonl\",\n",
    "    ],\n",
    "    intent_level=\"high\",\n",
    "    task_type=\"if\"\n",
    "    )\n",
    "print(f\"{f1:.6f}\")\n",
    "\n",
    "# f1 = report_result_llama(\n",
    "#     [\n",
    "#         \"saves/LLaMA2-7B-Chat/zero_shot/trecis-if/results_if_val_high/generated_predictions.jsonl\",\n",
    "#         \"saves/LLaMA2-7B-Chat/zero_shot/trecis-if/results_if_val_high_1/generated_predictions.jsonl\",\n",
    "#     ],\n",
    "#     intent_level=\"high\",\n",
    "#     task_type=\"if\"\n",
    "#     )\n",
    "# print(f\"{f1:.6f}\")\n",
    "\n",
    "# f1 = report_result_llama(\n",
    "#     [\n",
    "#         \"saves/LLaMA2-7B-Chat/zero_shot/trecis-if/results_if_test_high/generated_predictions.jsonl\",\n",
    "#         \"saves/LLaMA2-7B-Chat/zero_shot/trecis-if/results_if_test_high_1/generated_predictions.jsonl\",\n",
    "#     ],\n",
    "#     intent_level=\"high\",\n",
    "#     task_type=\"if\"\n",
    "#     )\n",
    "# print(f\"{f1:.6f}\")\n",
    "\n",
    "# print(\"llama-2-7B-chat zero-shot on val set (top)\")\n",
    "# report_result_llama(Path(\"saves/LLaMA2-7B-Chat/zero_shot/trecis-mc/results_val_top/generated_predictions.jsonl\"))\n",
    "# print(\"llama-2-7B-chat zero-shot on sampled test set (top)\")\n",
    "# report_result_llama(Path(\"saves/LLaMA2-7B-Chat/zero_shot/trecis-mc/results_test_top/generated_predictions.jsonl\"))\n",
    "\n",
    "# print(\"llama-2-7B-chat zero-shot on val set (high)\")\n",
    "# report_result_llama(\n",
    "#     Path(\"saves/LLaMA2-7B-Chat/zero_shot/trecis-mc/results_val_high/generated_predictions.jsonl\"),\n",
    "#     intent_level=\"high\"\n",
    "#     )\n",
    "# print(\"llama-2-7B-chat zero-shot on sampled test set (high)\")\n",
    "# report_result_llama(\n",
    "#     Path(\"saves/LLaMA2-7B-Chat/zero_shot/trecis-mc/results_test_high/generated_predictions.jsonl\"),\n",
    "#     intent_level=\"high\"\n",
    "#     )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
